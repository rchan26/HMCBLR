---
title: "Simulating from the Bayesian logistic regression posterior"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{BLR_sampling}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(HMCBLR)
```

The posterior for Bayesian logistic regression with $\mathcal{N}\left(\mu_{j}, C\sigma_{\beta_{j}}^{2}\right)$ priors for the coefficients $\beta_{j}$ for $j=0,\dots,p$ is given by
$$
    \pi(\beta | y) = \left[ \prod_{i=1}^{n} \frac{e^{X_{i}\beta \cdot y_{i}}}{1+e^{X_{i}\beta}} \right] \cdot \left[ \prod_{j=0}^{p} \frac{1}{\sqrt{2\pi C\sigma_{\beta_{j}}^{2}}} \exp \left( - \frac{(\beta_{j}-\mu_{j})^{2}}{2C\sigma_{\beta_{j}}^{2}} \right) \right]
$$
where $y$ is the binary response variable, $X$ is the design matrix so $X_{i} \beta = \beta_{0} + \beta_{1} X_{i1} + \cdots \beta_{p} X_{ip}$.

Using the `simulate_data` function (also see the *data_manipulation* vignette for more examples using this function), we can simulate data from a logistic regression model.

```{r}
seed <- 2021
set.seed(seed)
nsamples <- 1000
ndata <- 1000
n_cores <- parallel::detectCores()
true_beta <- c(-3, 1.2, -0.5, 0.8, 3)
frequencies <- c(0.2, 0.3, 0.5, 0.01)
# simulate data set
simulated_data <- simulate_LR_data(N = ndata,
                                   alpha = true_beta[1],
                                   frequencies = frequencies,
                                   coefficients = true_beta[2:length(true_beta)],
                                   seed = seed)
```

We need to use `unique_row_count` to obtain the unique row counts of the full data set that we pass into the `hmc_sample_BLR` function to simulate from the posterior distribution. We have this unique row count mechanism so that we can accelerate our sampler by grouping likelihood evaluations. This can reduce computation quite significantly if there are a number of repeated data entries.

```{r}
full_data_count <- unique_row_count(y = simulated_data[,1],
                                    X = cbind('intercept' = rep(1, ndata), simulated_data[,2:ncol(simulated_data)]))$full_data_count
print(full_data_count)
```

We can then sample from our posterior using:

```{r}
full_posterior <- hmc_sample_BLR(full_data_count = full_data_count,
                                 C = 1,
                                 prior_means = rep(0, 5),
                                 prior_variances = rep(1, 5),
                                 iterations = nsamples + 10000,
                                 warmup = 10000,
                                 chains = 1,
                                 seed = seed,
                                 output = T)
```

Suppose that we want to first split our sample into $C$ subsets and then independently sample from the posterior distribution using each subset of data (we call these *sub-posteriors*), then we can use the `split_data` function to first split the data and pass this into the `hmc_base_sampler_BLR` function.

```{r}
data_split_4 <- split_data(simulated_data, y_col_index = 1, X_col_index = 2:ncol(simulated_data), C = 4, as_dataframe = F)
sub_posteriors_4 <- hmc_base_sampler_BLR(nsamples = nsamples,
                                         data_split = data_split_4,
                                         C = 4, 
                                         prior_means = rep(0, 5),
                                         prior_variances = rep(1, 5),
                                         warmup = 10000,
                                         seed = seed,
                                         output = FALSE)
```
